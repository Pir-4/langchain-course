{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-26T20:40:28.778982Z",
     "start_time": "2026-02-26T20:40:28.768098Z"
    }
   },
   "source": [
    "from chats import llm\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = \"\"\"\n",
    "Answer the user's query based on the context below.\n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "promt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:38:18.954164Z",
     "start_time": "2026-02-26T20:38:18.893311Z"
    }
   },
   "cell_type": "code",
   "source": "promt_template.input_variables",
   "id": "af69855f30974253",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'query']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:40:30.482542Z",
     "start_time": "2026-02-26T20:40:30.444944Z"
    }
   },
   "cell_type": "code",
   "source": "promt_template.messages",
   "id": "ddd839be7dd7a58e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:42:23.629248Z",
     "start_time": "2026-02-26T20:42:23.613656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from  langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ],
   "id": "b0c315a5b8adc858",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:42:27.332645Z",
     "start_time": "2026-02-26T20:42:27.288555Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_template",
   "id": "f0ff80bb238265d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:43:46.129939Z",
     "start_time": "2026-02-26T20:43:46.096789Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_template.input_variables",
   "id": "5ce6bd03dbfd027",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'query']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:44:04.523999Z",
     "start_time": "2026-02-26T20:44:04.487952Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_template.messages",
   "id": "2532458efedf20cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:46:12.093866Z",
     "start_time": "2026-02-26T20:46:12.072440Z"
    }
   },
   "cell_type": "code",
   "source": "pipeline = prompt_template | llm",
   "id": "88d01e3fe08e1c2c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:47:09.384102Z",
     "start_time": "2026-02-26T20:47:09.357203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context = \"\"\"Aurelio AI is an AI company developing tooling for AI\n",
    "engineers. Their focus is on language AI with the team having strong\n",
    "expertise in building AI agents and a strong background in\n",
    "information retrieval.\n",
    "\n",
    "The company is behind several open source frameworks, most notably\n",
    "Semantic Router and Semantic Chunkers. They also have an AI\n",
    "Platform providing engineers with tooling to help them build with\n",
    "AI. Finally, the team also provides development services to other\n",
    "organizations to help them bring their AI tech to market.\n",
    "\n",
    "Aurelio AI became LangChain Experts in September 2024 after a long\n",
    "track record of delivering AI solutions built with the LangChain\n",
    "ecosystem.\"\"\"\n",
    "\n",
    "query = \"what does Aurelio AI do?\""
   ],
   "id": "34423cd4fa801e0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:48:29.935580Z",
     "start_time": "2026-02-26T20:47:56.188087Z"
    }
   },
   "cell_type": "code",
   "source": "pipeline.invoke({\"query\": query, \"context\": context})",
   "id": "9867f720174c4b30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Aurelio AI is an AI company that develops tooling and frameworks for AI engineers, with a focus on language AI. They specialize in building AI agents and information retrieval systems. Their work includes open-source projects like **Semantic Router** and **Semantic Chunkers**, an AI Platform for developers, and development services to help organizations bring AI technologies to market. They also became **LangChain Experts** in September 2024, highlighting their expertise in the LangChain ecosystem.', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-02-26T20:48:29.841654Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33333476500, 'load_duration': 3829526084, 'prompt_eval_count': 193, 'prompt_eval_duration': 2568007041, 'eval_count': 278, 'eval_duration': 26625937668, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019c9bb5-4e45-7990-abb0-c9966b0e1759-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 193, 'output_tokens': 278, 'total_tokens': 471})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:54:53.918013Z",
     "start_time": "2026-02-26T20:54:53.899185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])"
   ],
   "id": "cc0e4726e4c2639c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:54:56.920619Z",
     "start_time": "2026-02-26T20:54:56.903538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    {\"input\": \"Here is query #1\", \"output\": \"Here is the answer #1\"},\n",
    "    {\"input\": \"Here is query #2\", \"output\": \"Here is the answer #2\"},\n",
    "    {\"input\": \"Here is query #3\", \"output\": \"Here is the answer #3\"},\n",
    "]"
   ],
   "id": "500bde0951ff2d67",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:56:20.797175Z",
     "start_time": "2026-02-26T20:56:20.765712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt= example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ],
   "id": "6007e510ee5b1ea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Here is query #1\n",
      "AI: Here is the answer #1\n",
      "Human: Here is query #2\n",
      "AI: Here is the answer #2\n",
      "Human: Here is query #3\n",
      "AI: Here is the answer #3\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:58:01.569428Z",
     "start_time": "2026-02-26T20:58:01.548516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_system_prompt = \"\"\"\n",
    "Answer the user's query based on the context below.\n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Always answer in markdown format. When doing so please\n",
    "provide headers, short summaries, follow with bullet\n",
    "points, then conclude.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\""
   ],
   "id": "3ce935c8d2276d85",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:01:13.943071Z",
     "start_time": "2026-02-26T21:00:18.283635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template.messages[0].prompt.template = new_system_prompt\n",
    "\n",
    "out = pipeline.invoke({\"query\": query, \"context\": context}).content\n",
    "print(out)"
   ],
   "id": "4a79d4127a5aa1b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# What Does Aurelio AI Do?\n",
      "\n",
      "## Summary  \n",
      "Aurelio AI is an AI company specializing in **language AI tools** for engineers. They focus on building **AI agents** and **information retrieval systems**, while also offering open-source frameworks, development platforms, and services to help organizations deploy AI solutions.\n",
      "\n",
      "## Key Activities  \n",
      "- **Develops Tooling for AI Engineers**: Creates tools and frameworks to streamline AI development.  \n",
      "- **Language AI Expertise**: Specializes in natural language processing and AI agent development.  \n",
      "- **Open-Source Frameworks**:  \n",
      "  - **Semantic Router**: For routing queries to the right AI models.  \n",
      "  - **Semantic Chunkers**: For text segmentation and processing.  \n",
      "- **AI Platform**: Provides engineers with tools to build and deploy AI applications.  \n",
      "- **Development Services**: Offers consulting to help organizations bring AI products to market.  \n",
      "- **LangChain Integration**: Became a **LangChain Expert** in September 2024, leveraging their long history with the ecosystem.  \n",
      "\n",
      "## Conclusion  \n",
      "Aurelio AI combines **research**, **open-source innovation**, and **practical development services** to empower engineers and organizations in building advanced language AI solutions.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:02:41.965452Z",
     "start_time": "2026-02-26T21:02:41.836427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out))"
   ],
   "id": "c5fe286e3d115e27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# What Does Aurelio AI Do?\n\n## Summary  \nAurelio AI is an AI company specializing in **language AI tools** for engineers. They focus on building **AI agents** and **information retrieval systems**, while also offering open-source frameworks, development platforms, and services to help organizations deploy AI solutions.\n\n## Key Activities  \n- **Develops Tooling for AI Engineers**: Creates tools and frameworks to streamline AI development.  \n- **Language AI Expertise**: Specializes in natural language processing and AI agent development.  \n- **Open-Source Frameworks**:  \n  - **Semantic Router**: For routing queries to the right AI models.  \n  - **Semantic Chunkers**: For text segmentation and processing.  \n- **AI Platform**: Provides engineers with tools to build and deploy AI applications.  \n- **Development Services**: Offers consulting to help organizations bring AI products to market.  \n- **LangChain Integration**: Became a **LangChain Expert** in September 2024, leveraging their long history with the ecosystem.  \n\n## Conclusion  \nAurelio AI combines **research**, **open-source innovation**, and **practical development services** to empower engineers and organizations in building advanced language AI solutions."
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:03:20.115853Z",
     "start_time": "2026-02-26T21:03:20.096378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can you explain gravity?\",\n",
    "        \"output\": (\n",
    "            \"## Gravity\\n\\n\"\n",
    "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
    "            \"### Discovery\\n\\n\"\n",
    "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n\"\n",
    "            \"* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n\"\n",
    "            \"### In General Relativity\\n\\n\"\n",
    "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
    "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
    "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
    "            \"### Gravitons\\n\\n\"\n",
    "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
    "            \"* They have not yet been detected.\\n\\n\"\n",
    "            \"**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": (\n",
    "            \"## France\\n\\n\"\n",
    "            \"The capital of France is Paris.\\n\\n\"\n",
    "            \"### Origins\\n\\n\"\n",
    "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to a Celtic people living in the area.\\n\"\n",
    "            \"* The Romans named the city Lutetia, which means \\\"the place where the river turns\\\".\\n\"\n",
    "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n\"\n",
    "            \"**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]"
   ],
   "id": "741af20eba9486ac",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:04:12.802221Z",
     "start_time": "2026-02-26T21:04:12.789093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt= example_prompt,\n",
    "    examples=examples,\n",
    ")\n"
   ],
   "id": "af444e38ef4bfb58",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:04:14.420038Z",
     "start_time": "2026-02-26T21:04:14.398755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = few_shot_prompt.format()\n",
    "display(Markdown(out))"
   ],
   "id": "c4a457893e9d2d72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Human: Can you explain gravity?\nAI: ## Gravity\n\nGravity is one of the fundamental forces in the universe.\n\n### Discovery\n\n* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\n* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\n\n### In General Relativity\n\n* Gravity is described as the curvature of spacetime.\n* The more massive an object is, the more it curves spacetime.\n* This curvature is what causes objects to fall towards each other.\n\n### Gravitons\n\n* Gravitons are hypothetical particles that mediate the force of gravity.\n* They have not yet been detected.\n\n**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\n\n\nHuman: What is the capital of France?\nAI: ## France\n\nThe capital of France is Paris.\n\n### Origins\n\n* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\n* The Romans named the city Lutetia, which means \"the place where the river turns\".\n* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\n\n**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\n\n"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:05:58.317049Z",
     "start_time": "2026-02-26T21:05:58.306230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", new_system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{query}\"),\n",
    "])"
   ],
   "id": "a58e89fab59184f6",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T21:08:05.851173Z",
     "start_time": "2026-02-26T21:07:15.249858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = prompt_template | llm\n",
    "out = pipeline.invoke({\"query\": query, \"context\": context}).content\n",
    "display(Markdown(out))"
   ],
   "id": "b5e692aaad7140fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## What Does Aurelio AI Do?\n\nAurelio AI is an AI company specializing in **language AI tools** and **AI engineering solutions**. Their work focuses on enabling developers and organizations to build advanced AI systems efficiently.\n\n### Key Activities  \n- **Develops Open-Source Frameworks**:  \n  * Semantic Router  \n  * Semantic Chunkers  \n- **Provides AI Tooling**:  \n  * An AI Platform offering tools for AI development and integration.  \n- **Offers Development Services**:  \n  * Helps organizations bring AI technologies to market.  \n- **LangChain Expertise**:  \n  * Became a LangChain Expert in September 2024, leveraging their experience with the LangChain ecosystem.  \n\n### Core Focus Areas  \n- **Language AI**: Specializes in natural language processing and AI agent development.  \n- **Information Retrieval**: Leverages expertise in retrieving and organizing data for AI systems.  \n\n**To conclude**, Aurelio AI empowers AI engineers and organizations with tools, frameworks, and services to build and deploy advanced language AI solutions."
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T20:17:49.036566Z",
     "start_time": "2026-02-28T20:17:48.987622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_cot_system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "You MUST answer the question directly without any other\n",
    "text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "no_cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", no_cot_system_prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ],
   "id": "f523fcd5422ecec5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T20:21:25.940485Z",
     "start_time": "2026-02-28T20:20:34.968606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = (\n",
    "    \"How many keystrokes are needed to type the numbers from 1 to 500?\"\n",
    ")\n",
    "\n",
    "no_cot_pipeline = no_cot_prompt_template | llm\n",
    "no_cot_result = no_cot_pipeline.invoke({\"query\": query}).content\n",
    "print(no_cot_result)"
   ],
   "id": "663f722b4debfc95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T20:23:24.978553Z",
     "start_time": "2026-02-28T20:23:24.964837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the chain-of-thought prompt template\n",
    "cot_system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "To answer the question, you must:\n",
    "\n",
    "- List systematically and in precise detail all\n",
    "  subproblems that need to be solved to answer the\n",
    "  question.\n",
    "- Solve each sub problem INDIVIDUALLY and in sequence.\n",
    "- Finally, use everything you have worked through to\n",
    "  provide the final answer.\n",
    "\"\"\"\n",
    "\n",
    "cot_system_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", cot_system_prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "cot_system_pipeline = cot_system_template | llm"
   ],
   "id": "d9c1d49ae4e08ff6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T20:27:22.618091Z",
     "start_time": "2026-02-28T20:23:54.659209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cot_result = cot_system_pipeline.invoke({\"query\": query}).content\n",
    "display(Markdown(cot_result))"
   ],
   "id": "2a7f3f217648f9a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "To determine the total number of keystrokes required to type the numbers from 1 to 500, we systematically analyze the problem by categorizing numbers based on their digit lengths and calculating the keystrokes for each category.\n\n---\n\n### **Step 1: Categorize Numbers by Digit Length**\n\n1. **Single-digit numbers (1 to 9):**\n   - These are the numbers from 1 to 9.\n   - Each number has **1 digit**.\n   - Total numbers: $9$\n   - Keystrokes: $9 \\times 1 = 9$\n\n2. **Two-digit numbers (10 to 99):**\n   - These are the numbers from 10 to 99.\n   - Each number has **2 digits**.\n   - Total numbers: $99 - 10 + 1 = 90$\n   - Keystrokes: $90 \\times 2 = 180$\n\n3. **Three-digit numbers (100 to 500):**\n   - These are the numbers from 100 to 500.\n   - Each number has **3 digits**.\n   - Total numbers: $500 - 100 + 1 = 401$\n   - Keystrokes: $401 \\times 3 = 1203$\n\n---\n\n### **Step 2: Sum the Keystrokes**\n\nAdd the keystrokes from all categories:\n\n$$\n\\text{Total keystrokes} = 9 + 180 + 1203 = 1392\n$$\n\n---\n\n### **Final Answer**\n\n$$\n\\boxed{1392}\n$$"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T20:31:16.096656Z",
     "start_time": "2026-02-28T20:31:16.084874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt_2 = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt_2),\n",
    "    (\"user\", \"{query}\"),\n",
    "])\n",
    "pepeline = prompt_template_2 | llm"
   ],
   "id": "b04cb0df957169b1",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-28T20:31:17.497270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = pepeline.invoke({\"query\": query}).content\n",
    "display(Markdown(result))"
   ],
   "id": "7a218e05433e8a54",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
